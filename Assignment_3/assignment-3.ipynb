{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8805935,"sourceType":"datasetVersion","datasetId":5296140},{"sourceId":8824908,"sourceType":"datasetVersion","datasetId":5309352}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Importing the Packages","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms\nfrom PIL import Image\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:41:28.610137Z","iopub.execute_input":"2024-07-04T09:41:28.610664Z","iopub.status.idle":"2024-07-04T09:41:28.618861Z","shell.execute_reply.started":"2024-07-04T09:41:28.610631Z","shell.execute_reply":"2024-07-04T09:41:28.617998Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# **Main Model**","metadata":{}},{"cell_type":"code","source":"# accessing the images and changing the labels into binary encoding \nclass CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, transform=None):\n        self.img_labels = pd.read_csv(annotations_file)\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_name = self.img_labels.iloc[idx, 0]\n        if not img_name.lower().endswith('.png'):\n            img_name += '.png'\n        img_path = os.path.join(self.img_dir, img_name)\n        image = Image.open(img_path).convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        \n        label_ball_1 = self.img_labels.iloc[idx, 1]\n        label_ball_2 = self.img_labels.iloc[idx, 2]\n        labels = [0, 0, 0, 0] \n        labels[label_ball_1] = 1\n        labels[label_ball_2] = 1\n        \n        return image, torch.tensor(labels, dtype=torch.float32)\n\n# paths for annotations and the images directory for our training\nannotations_file = \"/kaggle/input/sportsball-ann/SportBalls/LABELS/train_labels.csv\"\nimg_dir = \"/kaggle/input/sportsball-ann/SportBalls/Train\"\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n])\n\nfull_dataset = CustomImageDataset(annotations_file, img_dir, transform=transform)\n\n# Splitting the data into train and validation\ntrain_ratio = 0.8\ntotal_size = len(full_dataset)\ntrain_size = int(train_ratio * total_size)\nval_size = total_size - train_size\ntrain_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n\n# Create DataLoaders for each subset of train and validation\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n\n# checking the train loader and validation loader sizes after batching\nprint(\"Train Loader Size:\", len(train_loader))\nprint(\"Validation Loader Size:\", len(val_loader))\n\n\nclass BallClassifierCNN(nn.Module):\n    def __init__(self):\n        super(BallClassifierCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n        self.bn2 = nn.BatchNorm2d(64)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n        self.dropout = nn.Dropout(0.2)\n        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n        self.fc2 = nn.Linear(128, 4)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n        x = x.view(-1, 64 *16 * 16) \n        x = self.dropout(F.relu(self.fc1(x)))\n        x = self.fc2(x)\n        return x\n\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu') \nmodel = BallClassifierCNN().to(device)\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n\nprint(model)\n\n# Training loop\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n    with tqdm(train_loader, unit=\"batch\") as tepoch:\n        for images, labels in tepoch:\n            tepoch.set_description(f\"Epoch {epoch + 1}\")\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            # Forward pass\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            # Backward pass\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            predicted = torch.sigmoid(outputs) > 0.5\n            total_train += labels.numel()\n            correct_train += (predicted == labels).sum().item()\n            \n            tepoch.set_postfix(loss=loss.item())\n\n    train_accuracy = 100 * correct_train / total_train\n    train_loss = running_loss / len(train_loader)\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%')\n    \n    # Validation loop\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            predicted = torch.sigmoid(outputs) > 0.5\n            total += labels.numel()\n            correct += (predicted == labels).sum().item()\n\n    val_accuracy = 100 * correct / total\n    val_loss_avg = val_loss / len(val_loader)\n    print(f'Validation Loss: {val_loss_avg:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n\nprint('Training complete.')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:57:23.317372Z","iopub.execute_input":"2024-07-04T09:57:23.317852Z","iopub.status.idle":"2024-07-04T09:59:37.862880Z","shell.execute_reply.started":"2024-07-04T09:57:23.317815Z","shell.execute_reply":"2024-07-04T09:59:37.861937Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Train Loader Size: 125\nValidation Loader Size: 32\nBallClassifierCNN(\n  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (dropout): Dropout(p=0.2, inplace=False)\n  (fc1): Linear(in_features=16384, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=4, bias=True)\n)\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 125/125 [00:10<00:00, 11.76batch/s, loss=0.192]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [1/10], Train Loss: 0.3974, Train Accuracy: 81.75%\nValidation Loss: 0.1995, Validation Accuracy: 94.09%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 125/125 [00:11<00:00, 11.18batch/s, loss=0.126] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [2/10], Train Loss: 0.1577, Train Accuracy: 94.89%\nValidation Loss: 0.0938, Validation Accuracy: 97.45%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 125/125 [00:11<00:00, 10.98batch/s, loss=0.1]   \n","output_type":"stream"},{"name":"stdout","text":"Epoch [3/10], Train Loss: 0.0997, Train Accuracy: 97.09%\nValidation Loss: 0.0844, Validation Accuracy: 97.38%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 125/125 [00:11<00:00, 11.22batch/s, loss=0.083] \n","output_type":"stream"},{"name":"stdout","text":"Epoch [4/10], Train Loss: 0.0773, Train Accuracy: 97.71%\nValidation Loss: 0.0529, Validation Accuracy: 98.61%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 125/125 [00:10<00:00, 11.65batch/s, loss=0.0452]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [5/10], Train Loss: 0.0636, Train Accuracy: 98.19%\nValidation Loss: 0.0617, Validation Accuracy: 98.12%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 125/125 [00:10<00:00, 11.75batch/s, loss=0.0739]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [6/10], Train Loss: 0.0550, Train Accuracy: 98.36%\nValidation Loss: 0.0466, Validation Accuracy: 98.78%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 125/125 [00:11<00:00, 10.90batch/s, loss=0.0979]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [7/10], Train Loss: 0.0537, Train Accuracy: 98.43%\nValidation Loss: 0.0537, Validation Accuracy: 98.21%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 125/125 [00:11<00:00, 11.28batch/s, loss=0.0581]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [8/10], Train Loss: 0.0454, Train Accuracy: 98.66%\nValidation Loss: 0.0396, Validation Accuracy: 98.89%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 125/125 [00:10<00:00, 11.49batch/s, loss=0.0139]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [9/10], Train Loss: 0.0412, Train Accuracy: 98.80%\nValidation Loss: 0.0414, Validation Accuracy: 98.83%\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 125/125 [00:11<00:00, 11.19batch/s, loss=0.0246]\n","output_type":"stream"},{"name":"stdout","text":"Epoch [10/10], Train Loss: 0.0364, Train Accuracy: 98.89%\nValidation Loss: 0.0385, Validation Accuracy: 98.99%\nTraining complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'BallClassifierModel.pth')","metadata":{"execution":{"iopub.status.busy":"2024-07-04T09:59:51.038084Z","iopub.execute_input":"2024-07-04T09:59:51.038970Z","iopub.status.idle":"2024-07-04T09:59:51.061892Z","shell.execute_reply.started":"2024-07-04T09:59:51.038919Z","shell.execute_reply":"2024-07-04T09:59:51.061001Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# **Predicting the Labels of the Test Data**","metadata":{}},{"cell_type":"code","source":"test_dir = \"/kaggle/input/sportsball/SportBalls/Test\"\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n])\n\n# Loading  the trained model  \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nmodel = BallClassifierCNN()\nmodel.load_state_dict(torch.load('/kaggle/working/BallClassifierModel.pth'))\nmodel.to(device)\n# setting the model to evaluation state\nmodel.eval()\n\n# Function to predict labels for a single image\ndef predict_image(image_path, model, transform, device):\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0).to(device)\n    with torch.no_grad():\n        output = model(image)\n        prediction = torch.sigmoid(output) > 0.5\n    return prediction.cpu().numpy().astype(int).flatten()\n\n# make predictions for the test images\ntest_predictions = []\nimage_paths = []\nfor img_name in tqdm(os.listdir(test_dir), desc=\"Predicting\"):\n    img_path = os.path.join(test_dir, img_name)\n    if img_path.split(\".\")[1] == \"csv\":\n        continue\n    else: \n        pred = predict_image(img_path, model, transform, device)\n        test_predictions.append(pred)\n        image_paths.append(img_name)\n\n# saving the test precictions  to a CSV file\ntest_preds = pd.DataFrame(test_predictions, columns=['baseball', 'basketball', 'vollebyball', 'soccerball'])\ntest_preds.insert(0, 'Image', image_paths)\ntest_preds.to_csv('test_preds.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:00:20.014468Z","iopub.execute_input":"2024-07-04T10:00:20.015449Z","iopub.status.idle":"2024-07-04T10:00:26.241780Z","shell.execute_reply.started":"2024-07-04T10:00:20.015405Z","shell.execute_reply":"2024-07-04T10:00:26.240781Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Predicting: 100%|██████████| 1002/1002 [00:05<00:00, 174.10it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# **Predicting the labels of Train Data**","metadata":{}},{"cell_type":"code","source":"\ntrain_dir = \"/kaggle/input/sportsball-ann/SportBalls/Train\"\ntransform = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n])\n\n# Load the model  \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.eval()\n\n# predicting labels for a single image\ndef predict_image(image_path, model, transform, device):\n    image = Image.open(image_path).convert(\"RGB\")\n    image = transform(image).unsqueeze(0).to(device)\n    with torch.no_grad():\n        output = model(image)\n        prediction = torch.sigmoid(output) > 0.5\n    return prediction.cpu().numpy().astype(int).flatten()\n\ntrain_predictions = []\nimage_paths = []\nfor img_name in tqdm(os.listdir(train_dir), desc=\"Predicting\"):\n    img_path = os.path.join(train_dir, img_name)\n    \n    pred = predict_image(img_path, model, transform, device)\n    train_predictions.append(pred)\n    image_paths.append(img_name)\n\ntrain_preds = pd.DataFrame(train_predictions, columns=['baseball', 'basketball', 'vollebyball', 'soccerball'])\ntrain_preds.insert(0, 'Image', image_paths)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:00:35.733315Z","iopub.execute_input":"2024-07-04T10:00:35.734103Z","iopub.status.idle":"2024-07-04T10:00:53.572547Z","shell.execute_reply.started":"2024-07-04T10:00:35.734068Z","shell.execute_reply":"2024-07-04T10:00:53.571530Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"Predicting: 100%|██████████| 10000/10000 [00:17<00:00, 570.03it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# sorting the images in the train_preds as they are irregular when taken from the directory for predictions\ntrain_preds['Numeric_Image'] = train_preds['Image'].str.extract(r'(\\d+)', expand=False).astype(int)\n\ntrain_preds_sorted = train_preds.sort_values('Numeric_Image').drop('Numeric_Image', axis=1)\n\ntrain_preds_sorted.reset_index(drop=True, inplace=True)\ntrain_preds_sorted.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:01:04.387488Z","iopub.execute_input":"2024-07-04T10:01:04.387819Z","iopub.status.idle":"2024-07-04T10:01:04.429549Z","shell.execute_reply.started":"2024-07-04T10:01:04.387793Z","shell.execute_reply":"2024-07-04T10:01:04.428607Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"           Image  baseball  basketball  vollebyball  soccerball\n0  img_00000.png         0           0            0           1\n1  img_00001.png         0           0            1           0\n2  img_00002.png         1           1            0           0\n3  img_00003.png         1           0            0           0\n4  img_00004.png         0           0            1           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>baseball</th>\n      <th>basketball</th>\n      <th>vollebyball</th>\n      <th>soccerball</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_00000.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_00001.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_00002.png</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_00003.png</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_00004.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# converting the given train  labels into binary\nannotations_file = \"/kaggle/input/sportsball-ann/SportBalls/LABELS/train_labels.csv\"\ntrain_labels = pd.read_csv(annotations_file, header= None)\ntrain_labels.columns = [\"Image\",\"Label-1\",\"Label-2\"]\nnew_labels = []\nfor row in range(train_labels.shape[0]):\n    label_ball_1 = train_labels.iloc[row, 1]\n    label_ball_2 = train_labels.iloc[row, 2]\n    labels = [0, 0, 0, 0]  \n    labels[label_ball_1] = 1\n    labels[label_ball_2] = 1\n    \n    current_label = [train_labels.loc[row,\"Image\"]] + labels\n    new_labels.append(current_label)\n\ntrain_true_labels = pd.DataFrame(new_labels,columns=train_preds_sorted.columns)\ntrain_true_labels.head()","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:01:22.301109Z","iopub.execute_input":"2024-07-04T10:01:22.301808Z","iopub.status.idle":"2024-07-04T10:01:23.106165Z","shell.execute_reply.started":"2024-07-04T10:01:22.301776Z","shell.execute_reply":"2024-07-04T10:01:23.105242Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"       Image  baseball  basketball  vollebyball  soccerball\n0  img_00000         0           0            1           1\n1  img_00001         0           0            1           0\n2  img_00002         1           1            0           0\n3  img_00003         1           0            0           0\n4  img_00004         0           0            1           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>baseball</th>\n      <th>basketball</th>\n      <th>vollebyball</th>\n      <th>soccerball</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_00000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_00001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_00002</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_00003</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_00004</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# comparing the each columns of train_true_labels and train_preds_sorted to get the accuracy of ball\naccuracy_df = {}\nfor i in train_preds_sorted.columns:\n    if i != \"Image\":\n        a=np.sum(train_preds_sorted[i] == train_true_labels[i]) / train_preds_sorted.shape[0] *100\n        accuracy_df[i] = a","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:01:24.943882Z","iopub.execute_input":"2024-07-04T10:01:24.944817Z","iopub.status.idle":"2024-07-04T10:01:24.953267Z","shell.execute_reply.started":"2024-07-04T10:01:24.944782Z","shell.execute_reply":"2024-07-04T10:01:24.952240Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"accuracy_df = pd.Series(accuracy_df)\nprint(accuracy_df)","metadata":{"execution":{"iopub.status.busy":"2024-07-04T10:01:29.418709Z","iopub.execute_input":"2024-07-04T10:01:29.419072Z","iopub.status.idle":"2024-07-04T10:01:29.426751Z","shell.execute_reply.started":"2024-07-04T10:01:29.419043Z","shell.execute_reply":"2024-07-04T10:01:29.425812Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"baseball       99.30\nbasketball     99.43\nvollebyball    99.00\nsoccerball     99.34\ndtype: float64\n","output_type":"stream"}]}]}